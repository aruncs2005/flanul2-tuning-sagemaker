{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('data/all.jsonl') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('data/all.jsonl')\n",
    "Lines1 = f1.readlines()\n",
    "\n",
    "quests, ans = [], []\n",
    "print(len(Lines1))\n",
    "for line in Lines1:\n",
    "    row = json.loads(line)\n",
    "    for answer in row[\"human_answers\"]:\n",
    "        quests.append(\"Prompt: \"+row[\"question\"])\n",
    "        ans.append(\"Response: \"+answer)\n",
    "    for answer in row[\"chatgpt_answers\"]:\n",
    "        quests.append(\"Prompt: \"+row[\"question\"])\n",
    "        ans.append(\"Response: \"+answer)\n",
    "\n",
    "print(f\"{len(quests)}--{len(ans)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "f1 = open('data/all.jsonl')\n",
    "Lines1 = f1.readlines()\n",
    "\n",
    "questions, answers = [], []\n",
    "print(len(Lines1))\n",
    "for line in Lines1[:20000]:\n",
    "    row = json.loads(line)\n",
    "    for answer in row[\"human_answers\"]:\n",
    "        questions.append(\"Prompt: \"+row[\"question\"])\n",
    "        answers.append(\"Response: \"+answer)\n",
    "    for answer in row[\"chatgpt_answers\"]:\n",
    "        questions.append(\"Prompt: \"+row[\"question\"])\n",
    "        answers.append(\"Response: \"+answer)\n",
    "\n",
    "test_file = open(\"data/test.jsonl\",\"w\")\n",
    "for line in Lines1[20000:]:\n",
    "    test_file.write(line)\n",
    "\n",
    "test_file.close()\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"question\"] = questions\n",
    "df[\"answer\"] = answers\n",
    "df = df.sample(frac = 1)\n",
    "print(len(df.index))\n",
    "df_train = df.iloc[:60000,:]\n",
    "df_val = df.iloc[60000:,:]\n",
    "\n",
    "df_train.to_csv(\"data/train.csv\", index=False)\n",
    "df_val.to_csv(\"data/val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_url = sess.upload_data(\n",
    "    path=\"data/train.csv\",\n",
    "    key_prefix=\"promptsds\",\n",
    ")\n",
    "\n",
    "valid_data_url = sess.upload_data(\n",
    "    path=\"data/val.csv\",\n",
    "    key_prefix=\"promptsds\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training file path {train_data_url}\")\n",
    "print(f\"validation file path {valid_data_url}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune FLAN T5 XXL (11b) on Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_name=\"sft-flanUl2-20b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {}\n",
    "SM_DATA_DIR = \"/opt/ml/input/data\" \n",
    "\n",
    "hyperparameters[\"model_name_or_path\"] = \"google/flan-ul2\"\n",
    "\n",
    "hyperparameters[\"model_dir\"] = f\"/opt/ml/model\"\n",
    "\n",
    "hyperparameters[\"train_file\"] = f\"{SM_DATA_DIR}/train/train.csv\"\n",
    "hyperparameters[\"validation_file\"] = f\"{SM_DATA_DIR}/valid/val.csv\"\n",
    "\n",
    "hyperparameters[\"per_device_train_batch_size\"] = 4\n",
    "hyperparameters[\"per_device_eval_batch_size\"] = 4\n",
    "hyperparameters[\"block_size\"] = 2048\n",
    "\n",
    "\n",
    "hyperparameters[\"num_train_epochs\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_options = {\n",
    "    \"enabled\":True,\n",
    "    \"parameters\": {                        # Required\n",
    "        \"pipeline_parallel_degree\": 1,     # Required\n",
    "        \"ddp\": True,\n",
    "        # parameters for sharded data parallelism\n",
    "        \"sharded_data_parallel_degree\": 16,              # Add this to activate sharded data parallelism\n",
    "        \"partitions\":1,\n",
    "        \"bf16\":True,\n",
    "        \"skip_tracing\": True\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "mpi_options = {\n",
    "    \"enabled\" : True,                      # Required\n",
    "    \"processes_per_host\" : 8,              # Required\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# launch with smp\n",
    "\n",
    "estimator = PyTorch(\n",
    "    base_job_name=base_job_name,\n",
    "    source_dir=\"./scripts\",\n",
    "    entry_point=\"train.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.13.1\",\n",
    "    py_version=\"py39\", \n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    "    distribution={\n",
    "        \"smdistributed\": {\"modelparallel\": smp_options},\n",
    "        \"mpi\": mpi_options\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 106/3752 [15:38<8:39:56,  8.56s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 106/3752 [15:38<8:40:00,  8.56s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 107/3752 [15:47<8:33:51,  8.46s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 107/3752 [15:47<8:33:53,  8.46s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 108/3752 [15:56<8:53:06,  8.78s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 108/3752 [15:56<8:53:08,  8.78s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 109/3752 [16:05<8:54:09,  8.80s/it]\n",
      "[1,mpirank:0,algo-1]<stdout>:[2023-05-02 02:51:12,046] [WARNING] [stage3.py:3068:step] 5 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding torch.cuda.empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 109/3752 [16:05<8:54:10,  8.80s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 110/3752 [16:13<8:45:58,  8.67s/it][1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 110/3752 [16:13<8:45:59,  8.67s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 111/3752 [16:22<8:51:24,  8.76s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 111/3752 [16:22<8:51:26,  8.76s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 112/3752 [16:31<8:44:50,  8.65s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 112/3752 [16:31<8:44:50,  8.65s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 113/3752 [16:41<9:08:26,  9.04s/it][1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 113/3752 [16:41<9:08:27,  9.04s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 114/3752 [16:49<8:57:57,  8.87s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 114/3752 [16:49<8:57:58,  8.87s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 115/3752 [16:58<8:52:57,  8.79s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 115/3752 [16:58<8:52:59,  8.79s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 116/3752 [17:06<8:47:43,  8.71s/it]\n",
      "[1,mpirank:0,algo-1]<stdout>:[2023-05-02 02:52:13,327] [WARNING] [stage3.py:3068:step] 5 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding torch.cuda.empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 116/3752 [17:06<8:47:43,  8.71s/it]\n",
      "[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 117/3752 [17:15<8:47:10,  8.70s/it]\n",
      "[1,mpirank:8,algo-2]<stderr>:#015  3%|▎         | 117/3752 [17:15<8:47:18,  8.70s/it]\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"train\":train_data_url,\"valid\":valid_data_url})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arunpy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2df149412efc1526e813459d121195dcad0cc0c344007149632d30b7359a266e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
